{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Recombine the final sequece and croos over between the weak links -> needed a custum function, maybe full deterministic\n",
    "- Stats and dataframe for the SNP and other variants\n",
    "- Implement gaps NNNNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import pairwise2\n",
    "from Bio import SeqIO\n",
    "import yaml\n",
    "from math import modf\n",
    "from Bio.Seq import Seq\n",
    "from inspyred import swarm\n",
    "from inspyred import benchmarks\n",
    "from inspyred import ec\n",
    "from inspyred.ec import selectors\n",
    "from collections import deque\n",
    "from itertools import combinations\n",
    "import random\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import collections\n",
    "from itertools import combinations\n",
    "from numba import njit\n",
    "import random\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "from joblib import Parallel, delayed\n",
    "import seaborn as sns\n",
    "import torch as tr\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m read_tf_1\u001b[38;5;241m.\u001b[39mget_shape()[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# read_tf = tf.strings.unicode_encode(read_tf, \"UTF-8\")\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mread_tf_1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'float' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "# Implementation using tensors\n",
    "\n",
    "read_1 = \"ATTTAggggTA\"\n",
    "read_1 = read_1.upper()\n",
    "\n",
    "read_2 = \"ATTCGGATCGA\"\n",
    "read_2 = read_2.upper()\n",
    "\n",
    "read_tf_2 = tf.constant([ord(c) for c in read_2])\n",
    "read_tf_1 = tf.constant([ord(c) for c in read_1])\n",
    "read_tf_1.get_shape()[0]\n",
    "# read_tf = tf.strings.unicode_encode(read_tf, \"UTF-8\")\n",
    "\n",
    "for i in range(read_tf_1.get_shape()[0]):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "too many arguments: expected 3, got 4",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 242\u001b[0m\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m weigth_matrix\n\u001b[0;32m    241\u001b[0m reads \u001b[38;5;241m=\u001b[39m comstum_reads(seq[:\u001b[38;5;241m300\u001b[39m], length_reads \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m, coverage \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m--> 242\u001b[0m \u001b[43meval_allign_np\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreads\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[23], line 216\u001b[0m, in \u001b[0;36meval_allign_np\u001b[1;34m(reads, par)\u001b[0m\n\u001b[0;32m    214\u001b[0m reads_1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;28mord\u001b[39m(c) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m reads[i]])\n\u001b[0;32m    215\u001b[0m reads_2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;28mord\u001b[39m(c) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m reads[j]])\n\u001b[1;32m--> 216\u001b[0m alignment \u001b[38;5;241m=\u001b[39m \u001b[43mnp_align_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreads_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreads_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpar\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmismatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpar\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m alignment[\u001b[38;5;241m2\u001b[39m]:\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m alignment[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mTypeError\u001b[0m: too many arguments: expected 3, got 4"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "from itertools import combinations\n",
    "from numba import njit\n",
    "from Bio import pairwise2\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from multiprocessing import Pool\n",
    "from joblib import Parallel, delayed\n",
    "import seaborn as sns\n",
    "import torch as tr\n",
    "import time\n",
    "\n",
    "seq = \"\"\n",
    "for seq_record in SeqIO.parse(\"C:\\\\Users\\\\filoa\\\\Desktop\\\\Programming_trials\\\\Assembler\\\\Data\\\\GCA_014117465.1_ASM1411746v1_genomic.fna\", format = \"fasta\"):\n",
    "    seq += str(seq_record.seq.upper())\n",
    "\n",
    "def comstum_reads(seq: str, length_reads = 10, coverage = 5, verbose = False) -> list:\n",
    "    \n",
    "    \"\"\"The function split the sequence in input in reads.\n",
    "    The splitting is done using random numbers, the amount of reds is given by: (len(seq)/length_read)*coverage.\n",
    "    \"\"\"\n",
    "\n",
    "    number_of_reads = int(len(seq)/length_reads) * coverage\n",
    "    starting_pos = random.sample(range(0, len(seq)-length_reads+1), number_of_reads)\n",
    "    reads = []\n",
    "\n",
    "    for num in starting_pos:\n",
    "        reads.append(seq[num:num+length_reads])\n",
    "\n",
    "    if verbose == True:\n",
    "        # This part has the only aim to show some stats on the reads\n",
    "        y = [0 for i in range(0,len(seq)+1)]\n",
    "        for i in starting_pos:\n",
    "            for j in range(i, i+length_reads+1):\n",
    "                y[j] += 1 \n",
    "        sns.set_theme(style=\"darkgrid\")\n",
    "        sns.lineplot(y)\n",
    "        print(f\"There are {y.count(0)} bases that have 0 coverage.\")\n",
    "\n",
    "    return reads\n",
    "\n",
    "@njit\n",
    "def np_score(align_list: list, zeros = True)->int:\n",
    "    length = len(align_list)\n",
    "    cnt = 0\n",
    "\n",
    "    for i in align_list:\n",
    "        if i == 0:\n",
    "            cnt += 1\n",
    "\n",
    "    if zeros:\n",
    "        return cnt\n",
    "    else:\n",
    "        return length-cnt\n",
    "\n",
    "@njit\n",
    "def reads_converter(read:list)->list:\n",
    "    return [ord(c) for c in read]\n",
    "\n",
    "@njit\n",
    "def np_align_func(seq_tuple:tuple, match:int = 3, mismatch:int = -2):\n",
    "    \"\"\"Do something\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialization of output, and since the the func return only one vaue for each the check will be if the saved value is greater or not\n",
    "    score = 0\n",
    "    diff = 0\n",
    "    switch = False\n",
    "\n",
    "    # String are transponed in number using the ord() func, tha aim is to use mathematichs instead of comparison between strigns.\n",
    "    seq_one = seq_tuple[0]\n",
    "    seq_two = seq_tuple[1]\n",
    "\n",
    "\n",
    "    # This is neceesary since knowing which one in the longest is also needed. seq_one is now scurely the longest\n",
    "    if seq_one.shape[0] >= seq_two.shape[0]:\n",
    "        max_lenght_seq = seq_one.shape[0]\n",
    "        min_length_seq = seq_two.shape[0]\n",
    "\n",
    "    else:\n",
    "        switch = True\n",
    "        max_lenght_seq = seq_two.shape[0]\n",
    "        min_length_seq = seq_two.shape[0]\n",
    "        seq_one, seq_two = seq_two, seq_one\n",
    "    \n",
    "    # Number of iterations\n",
    "    num_iteration_int = (max_lenght_seq + min_length_seq - 1) // 2\n",
    "    num_iteration = (max_lenght_seq + min_length_seq - 1) / 2\n",
    "    alone = False\n",
    "\n",
    "    if num_iteration > num_iteration_int:\n",
    "        alone = True\n",
    "\n",
    "    for i in range(num_iteration_int):\n",
    "        if i < min_length_seq:\n",
    "\n",
    "            align_forw = seq_one[:(i+1)] - seq_two[-(i+1):]\n",
    "            align_back = seq_two[:(i+1)] - seq_one[-(i+1):]\n",
    "\n",
    "            cnt = 0\n",
    "            for j in align_forw, align_back:\n",
    "                part_score = np_score(j)*match + np_score(j, zeros=False)*mismatch\n",
    "\n",
    "                if part_score > score:\n",
    "                    score = part_score\n",
    "                    if cnt > 0:\n",
    "                        diff = max_lenght_seq -i -1\n",
    "                    else:\n",
    "                        diff = -(min_length_seq -i -1)\n",
    "                cnt += 1\n",
    "        \n",
    "        if i >= min_length_seq:\n",
    "            align_forw = seq_one[i-min_length_seq+1:(i+1)] - seq_two[-(i+1):]\n",
    "            align_back = seq_one[-(i+1):-(i-min_length_seq+1)] - seq_two[:(i+1)]\n",
    "\n",
    "            cnt = 0\n",
    "            for j in align_forw, align_back:\n",
    "                part_score = np_score(j)*match + np_score(j, zeros=False)*mismatch\n",
    "\n",
    "                \n",
    "                if part_score > score:\n",
    "                    score = part_score\n",
    "                    if cnt > 0:\n",
    "                        diff = max_lenght_seq -i -1\n",
    "                    else:\n",
    "                        diff = -(min_length_seq -i -1)\n",
    "                cnt += 1 \n",
    "\n",
    "        if i == (num_iteration_int-1) and alone:\n",
    "            i += 1\n",
    "\n",
    "            align_forw = seq_one[i-min_length_seq+1:(i+1)] - seq_two[-(i+1):]\n",
    "            part_score = np_score(j)*match + np_score(j, zeros=False)*mismatch\n",
    "\n",
    "            if part_score > score:\n",
    "                score = part_score\n",
    "                diff = max_lenght_seq -i -1\n",
    "\n",
    "\n",
    "    return (score, diff, switch)\n",
    "\n",
    "def tensor_score(ord_sequence:list, zeros:True)->int:\n",
    "    raise NotImplemented\n",
    "\n",
    "def tensor_align(sequence_one:str, sequence_two:str):\n",
    "    raise NotImplemented\n",
    "\n",
    "def parallel_eval(num_reads:int):\n",
    "    comb = list(combinations(range(num_reads),2))\n",
    "    print(comb)\n",
    "\n",
    "    with Pool(processes=5)as pool:\n",
    "        results = pool.imap(np_align_func, comb)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def eval_allign_np(reads:list, par:list = [3, -2, -40, -40]) -> list:\n",
    "    \"\"\"Funtion that evaulate the alignment\n",
    "\n",
    "    reads: list of DNA sequences, each of the read is a string\n",
    "\n",
    "    par: list of parameters to performe the alignment\n",
    "    es (the examples represent the defoult parameters):\n",
    "    match_score = 2,\n",
    "    mismatch_penalty = -5,\n",
    "    gap_open_penalty = -22,\n",
    "    gap_extension_penalty = -5\n",
    "\n",
    "    output:\n",
    "    Matrix with the weigts (distances) between the reads (nodes)\n",
    "    In this matrix there are both the scores of the alignment, recognizable for the tipical integer score and\n",
    "    a flot number which is needed after to recompose the sequence, it indicates the overlapping bases.\n",
    "    Ex:\n",
    "        allignment score -> 2.0, 13.0, ...\n",
    "        overlapping number -> 12.24, 1.6, 19.56, ...\n",
    "            the number before the . is the starting base, while the one after is the ending base. To avoid problem later\n",
    "            with 0 a 1 digit is added for then remove it. So 12.30 become 12.301 but the corret indices are 12 and 30.\n",
    "\n",
    "        These two numbers are link by the position in the matrix which are the trasposition\n",
    "        Score 14.0 in position (1,5) --> 12.34 in position (5,1). Only the score position is referred\n",
    "        to the direction of the edge.\n",
    "        1 ---> 5 with allignment score 14 and read_1 is overlapped with read_5 in positions from 12 to 34 (both included)\n",
    "\n",
    "    Example of a matrix with three reads:\n",
    "\n",
    "        | 1    | 2    | 3    \n",
    "     1  | 0    |3.0   |12.231 \n",
    "     2  |34.601|  0   | 23.0\n",
    "     3  | 18.0 |45.701|  0\n",
    "    \"\"\"\n",
    "    length = len(reads)\n",
    "    # initialization of the matrices\n",
    "    weigth_matrix = np.zeros((length, length))\n",
    "\n",
    "    # The score of the allingment of read[1] to read[2] is the same of the opposite (read[2] to read[1])\n",
    "    # So when the function found the diretionality of the allignment put the score in rigth spot and a 0 in the wrong one.\n",
    "    visited = collections.deque([j for j in range(length)])\n",
    "\n",
    "    # with Pool() as pool:\n",
    "    #     results = pool.imap_unordered(np_align_func, (reads_1, reads_2))\n",
    "    \n",
    "    for i in tqdm(range(length)):\n",
    "\n",
    "        for j in visited:\n",
    "\n",
    "            if i == j:\n",
    "                # the diagonal of the matrix has 0 score because we are allinging the same sequence\n",
    "                continue\n",
    "            else:\n",
    "                # pairwise must return a positive score, if there is no one it return None\n",
    "                reads_1 = np.array([ord(c) for c in reads[i]])\n",
    "                reads_2 = np.array([ord(c) for c in reads[j]])\n",
    "                alignment = np_align_func(reads_1, reads_2, match = par[0], mismatch = par[1])\n",
    "\n",
    "                if alignment[2]:\n",
    "                    if alignment[1] > 0:\n",
    "                        weigth_matrix[j, i] = alignment[0]\n",
    "                        weigth_matrix[i, j] = float(f\"{0}.{abs(alignment[1])}\")\n",
    "                    \n",
    "                    else:\n",
    "                        weigth_matrix[i, j] = alignment[0]\n",
    "                        weigth_matrix[j, i] = float(f\"{0}.{abs(alignment[1])}\")\n",
    "\n",
    "                else:\n",
    "                    if alignment[1] > 0:\n",
    "                        weigth_matrix[j, i] = alignment[0]\n",
    "                        weigth_matrix[i, j] = float(f\"{0}.{abs(alignment[1])}\")\n",
    "                    \n",
    "                    else:\n",
    "                        weigth_matrix[i, j] = alignment[0]\n",
    "                        weigth_matrix[j, i] = float(f\"{0}.{abs(alignment[1])}\")\n",
    "\n",
    "                    \n",
    "        visited.popleft()\n",
    "    print(f\"Done matrix {len(weigth_matrix)}x{len(weigth_matrix)}\")\n",
    "    return weigth_matrix\n",
    "\n",
    "reads = comstum_reads(seq[:300], length_reads = 100, coverage = 3)\n",
    "eval_allign_np(reads=reads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing the final reconstruction function\n",
    "- return matrix\n",
    "- paralleize the coding/decoding in number\n",
    "- make a separe function for the consensus\n",
    "- probably is better to make lower the memory usage, since the consensus matrix will be in the same order of the length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the final cons_matrixonstruction function\n",
    "def final_consensus(path:list, reads:list, positions:list, length:int, max_coverage: int = 16, verbose:bool = False) ->str:\n",
    "    \"\"\"Rebluild from the list of reds, the path and the matrix with the scores the allignment.\n",
    "\n",
    "    path:list of tuple with edges --> [(1,3), (3,6), ...]\n",
    "    reads: list of the reads ---> [[67 84 65 71 71], [71 65 65 67], ...] \n",
    "    positions: is the weigth matrix, but will be considered only the number linked with the base overlapping\n",
    "\n",
    "    output: a matrix like structure of integers, which are embedding of the sequences   \n",
    "    \"\"\"\n",
    "\n",
    "    cons_matrix = np.zeros((max_coverage, length))\n",
    "    leng = len(cons_matrix[0])\n",
    "    cum_dif = 0\n",
    "    adding = np.zeros((max_coverage, int(length/100)))\n",
    "\n",
    "    for i,j in path:\n",
    "        # Here i,j represent the edge of the graph, to retrive not the score but the alignment\n",
    "        # the function needs the opposite position where there are these informations matrix[j][i]\n",
    "        # something like 12.22, 12 is the strating base 22 is the ending base of the overlapping, both included.\n",
    "\n",
    "        num = str(positions[j][i]).split(\".\")\n",
    "        dif = int(num[1])\n",
    "\n",
    "        if cons_matrix[0,0] == 0:\n",
    "            \n",
    "            for pos in range(0, len(reads[i])):\n",
    "                if cons_matrix[0, pos] != 0:\n",
    "                    cons_matrix = np.append(cons_matrix, adding, 1)\n",
    "                cons_matrix[0, pos] = reads[i][pos]\n",
    "            cum_dif += dif\n",
    "            temp = 0\n",
    "            for p in range(cum_dif, cum_dif + len(reads[j])):\n",
    "                if cons_matrix[1,pos] != 0:\n",
    "                    cons_matrix = np.append(cons_matrix, adding, 1)\n",
    "                cons_matrix[1, p] = reads[j][temp]\n",
    "                temp +=1\n",
    "\n",
    "        else:\n",
    "            cum_dif += dif\n",
    "            temp = 0\n",
    "            for pos in range(cum_dif, cum_dif + len(reads[j])):\n",
    "                if cons_matrix[0,pos]!= 0:\n",
    "                    cons_matrix = np.append(cons_matrix, adding, 1)\n",
    "                row = 0\n",
    "                while cons_matrix[row, pos] >= 1:\n",
    "                    row += 1\n",
    "                cons_matrix[row, pos] = reads[j][temp]\n",
    "                temp +=1\n",
    "\n",
    "    return cons_matrix\n",
    "\n",
    "def re_build(cons_matrix:list):\n",
    "        \n",
    "    cons_seq = \"\"\n",
    "    for i in range(0, len(cons_matrix)):\n",
    "        base = [int(x) for x in cons_matrix[:,i] if x > 0]\n",
    "        if base == []:\n",
    "            return cons_seq\n",
    "        ind = []\n",
    "        for num in [1,2,3,4]:\n",
    "            ind.append(base.count(num))\n",
    "        more_frequent = ind.index(max(ind)) + 1\n",
    "        # TODO stats\n",
    "        cons_seq += more_frequent\n",
    "\n",
    "    return cons_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallelization of the string of bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATTA\n",
      "[array([65, 84, 84, 65]), array([65, 84, 84, 65, 65]), array([65, 84, 84, 67, 71, 65, 84]), array([71, 71, 65, 71, 65, 71, 84, 67, 71, 71, 65])]\n",
      "['ATTA', 'ATTAA', 'ATTCGAT', 'GGAGAGTCGGA']\n"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import numpy as np\n",
    "from numba import jit\n",
    "\n",
    "\n",
    "def uni_code(read:str)->np.ndarray:\n",
    "    return np.array([ord(c) for c in read])\n",
    "\n",
    "def de_code(read:np.ndarray)->str:\n",
    "    return \"\".join([chr(c) for c in read])\n",
    "\n",
    "reads = [\"ATTA\", \"ATTAA\", \"ATTCGAT\", \"GGAGAGTCGGA\"]\n",
    "\n",
    "print(de_code(uni_code(reads[0])))\n",
    "\n",
    "results = Parallel(n_jobs=5)(delayed(uni_code)(i)for i in reads)\n",
    "print(results)\n",
    "\n",
    "re_results = Parallel(n_jobs=5)(delayed(de_code)(j)for j in results)\n",
    "print(re_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assembly class problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Assembly_problem():\n",
    "    \"\"\"Defines the de novo genome assembly problem.\n",
    "    \n",
    "    This class based on the Traveling Salesman problem defines the problem\n",
    "    of assembling a new genome for which no reference is available (de novo assembly):\n",
    "    given a set of genomic reads and their pairwise overlap score, find the\n",
    "    path generating the longest consensus sequence. This problem assumes that \n",
    "    the ``weights`` parameter is an *n*-by-*n* matrix of pairwise \n",
    "    overlap among *n* reads. This problem is treated as a \n",
    "    maximization problem, socfitness values are determined to be the \n",
    "    proportional to the sum of the overlaps between each couple of reads\n",
    "    (the weight of the edge) and the length of the final assembled sequence.\n",
    "    \n",
    "    Public Attributes:c\n",
    "    \n",
    "    - *weights* -- the two-dimensional list of pairwise overlap \n",
    "    - *components* -- the set of ``TrailComponent`` objects constructed\n",
    "      from the ``weights`` attribute, where the element is the ((source,\n",
    "      destination), weight)\n",
    "    - *bias* -- the bias in selecting the component of maximum desirability\n",
    "      when constructing a candidate solution for ant colony optimization \n",
    "      (default 0.5)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, reads, approximate_length):\n",
    "        self.weights = eval_allign(reads)\n",
    "        self.reads = reads\n",
    "        self.components = [swarm.TrailComponent((i, j), value=(self.weights[i][j])) for i, j in itertools.permutations(range(len(self.weights)), 2) if modf(self.weights[i,j])[0] == 0]\n",
    "        self.bias = 0.5\n",
    "        self.bounder = ec.DiscreteBounder([i for i in range(len(self.weights))])\n",
    "        self.best_path = None\n",
    "        self.maximize = True\n",
    "        self.length = approximate_length\n",
    "\n",
    "    def generator(self, random, args):\n",
    "            \"\"\"Return a candidate solution for an evolutionary computation.\"\"\"\n",
    "            locations = [i for i in range(len(self.weights))]\n",
    "            random.shuffle(locations)\n",
    "            return locations\n",
    "    \n",
    "    def constructor(self, random, args):\n",
    "        \"\"\"Return a candidate solution for an ant colony optimization.\"\"\"\n",
    "        self._use_ants = True\n",
    "        candidate = []\n",
    "        feasible_components = [1]   #Fake initialization to allow while loop to start\n",
    "        \n",
    "        # We need to visit all the nodes that CAN be visited, the graph is directed and not complete, meaning we can have no more nodes to visit without visiting all the\n",
    "        # nodes in the graph, thus, our termination condition is not visitin all the nodes but not having anymore feasible components\n",
    "        while len(feasible_components) > 0:\n",
    "            # At the start of the visit, all the components are feasible\n",
    "            if len(candidate) == 0:\n",
    "                feasible_components = self.components\n",
    "            elif len(candidate) == len(self.weights) - 1: # All the nodes have been visited\n",
    "                return candidate\n",
    "            else:\n",
    "                # Update feasible components and set of already visited nodes considering the node visited in the last iteration\n",
    "                last = candidate[-1]\n",
    "                already_visited = [c.element[0] for c in candidate]\n",
    "                already_visited.extend([c.element[1] for c in candidate])\n",
    "                already_visited = set(already_visited)\n",
    "                feasible_components = [c for c in self.components if c.element[0] == last.element[1] and c.element[1] not in already_visited]\n",
    "            if len(feasible_components) == 0:\n",
    "                return candidate\n",
    "            # Choose a feasible component\n",
    "            if random.random() <= self.bias:\n",
    "                next_component = max(feasible_components)\n",
    "            else:\n",
    "                next_component = selectors.fitness_proportionate_selection(random, feasible_components, {'num_selected': 1})[0]\n",
    "            candidate.append(next_component)\n",
    "        return candidate\n",
    "    \n",
    "    def cross_over(path:list, matrix:list)->list:\n",
    "        \"\"\"This function recombine the solution. Takes the path and the score associated to each edge\n",
    "        iterate over the path and switch two edge.\n",
    "        \"\"\"\n",
    "        imaginary_string = range(len(path))\n",
    "\n",
    "        min_1 = path.index(min([c.value for c in path]))\n",
    "        min_2 = path.index(min([c.value for c in path if (c.element[0] == min_1[0]) and (c.element[1] == min_1[1])]))\n",
    "        return None\n",
    "    \n",
    "    def evaluator(self, candidates, args):\n",
    "        \"\"\"Return the fitness values for the given candidates.\"\"\"\n",
    "        # TODO use normal distribution\n",
    "        fitness = []\n",
    "        for candidate in candidates:\n",
    "            total = 0\n",
    "            current_path = []\n",
    "            for c in candidate:\n",
    "                total += self.weights[c.element[0]][c.element[1]]\n",
    "                current_path.append(c)\n",
    "            # last = (candidate[-1].element[1], candidate[0].element[0])\n",
    "            # current_path=[(i.element[0],i.element[1]) for i in candidate] # maybe i is enough\n",
    "            # total += self.weights[last[0]][last[1]]\n",
    "            current_sequence = consensus_sequence(current_path, reads=self.reads, positions=self.weights, length=self.length)\n",
    "            length_score = abs((self.length-current_sequence)/self.length)\n",
    "            s = [5, 3, 1, 0.5, 0.2]\n",
    "            perc=[0, 0.01, 0.05, 0.08, 0.1, 0.2]\n",
    "            l_score = 0.1\n",
    "            for i in range(len(perc)-1):\n",
    "                if length_score >= perc[i] and length_score < perc[i+1]:\n",
    "                    l_score = s[perc.index(perc[i])]\n",
    "\n",
    "            if self.best_path == None:\n",
    "                self.best_path = current_path\n",
    "            \n",
    "            score = total * l_score\n",
    "            fitness.append(score)\n",
    "\n",
    "        return fitness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Align function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 5\n",
      "[65 84 84 65]\n",
      "[65 84 84 65 65]\n",
      "[65 84 84 67 71 65 84]\n",
      "[71 71 65 71 65 71 84 67 71 71 65]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6.0, 5, False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numba import jit\n",
    "import numpy as np\n",
    "from icecream import ic\n",
    "\n",
    "a = np.asarray([ord(c) for c in \"ATTA\"])\n",
    "b = np.array([ord(c) for c in \"ATTAA\"])\n",
    "c = np.array([ord(c) for c in \"ATTCGAT\"])\n",
    "d = np.array([ord(c) for c in \"GGAGAGTCGGA\"])\n",
    "\n",
    "print(len(a), len(b))\n",
    "\n",
    "print(f\"{a}\\n{b}\\n{c}\\n{d}\")\n",
    "\n",
    "@jit(nopython=True)\n",
    "def np_score(align_list: np.ndarray, zeros = True)->float:\n",
    "    \"\"\"This function is a replacement for the np function np.count_nonzero(), since inside the np_eval_function was needed to count the number of zeros (=matches).\n",
    "    However this function raise an error when run with the numba decorator.\n",
    "    \"\"\"\n",
    "    length = len(align_list)\n",
    "    cnt = 0\n",
    "\n",
    "    for i in align_list:\n",
    "        if i == 0:\n",
    "            cnt += 1\n",
    "\n",
    "    if zeros:\n",
    "        return float(cnt)\n",
    "    else:\n",
    "        return float(length-cnt)\n",
    "\n",
    "@jit(nopython=True)\n",
    "def np_align_func(seq_one:np.ndarray, seq_two:np.ndarray, match:int = 3, mismatch:int = -2) -> tuple:\n",
    "    \"\"\"This function is a replacement for the align function pirwise2.align.localms of the Bio library. This substitution has the aim of tackling the computational time of the\n",
    "    eval_alignment function. In order to decrease the time, there was the need to create a compilable function with numba, which was also capable of being parallelised.\n",
    "    As you can clearly see the function takes in input only the match and mismatch, because in this usage the gap introduction is useless.\n",
    "\n",
    "    seq_one, seq_two = input sequences already trasformed in byte\n",
    "    match, mismatch = integer value for the alignment\n",
    "\n",
    "    Note: the mismatch should be negative\n",
    "    Ex output: (12.0, 34, True)\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialization of outputs, the output is a tuple that contains: score of the alignment, a number indicating how the two reads align\n",
    "    # and if the two sequences have been inverted in order during the process\n",
    "    score = float(0)\n",
    "    diff = 0\n",
    "    switch = False\n",
    "\n",
    "    # Since knowing which one is the longest is needed \n",
    "    if seq_one.shape[0] >= seq_two.shape[0]:\n",
    "        max_lenght_seq = seq_one.shape[0]\n",
    "        min_length_seq = seq_two.shape[0]\n",
    "\n",
    "    else:\n",
    "        switch = True\n",
    "        max_lenght_seq = seq_two.shape[0]\n",
    "        min_length_seq = seq_one.shape[0]\n",
    "        seq_one, seq_two = seq_two, seq_one\n",
    "    \n",
    "    # Number of iterations\n",
    "    num_iteration_int = (max_lenght_seq + min_length_seq - 1) // 2\n",
    "    num_iteration = (max_lenght_seq + min_length_seq - 1) / 2\n",
    "    alone = False\n",
    "\n",
    "    if num_iteration > num_iteration_int:\n",
    "        alone = True\n",
    "\n",
    "    for i in range(num_iteration_int):\n",
    "        if i < min_length_seq:\n",
    "\n",
    "            align_forw = seq_one[:(i+1)] - seq_two[-(i+1):]\n",
    "            align_back = seq_two[:(i+1)] - seq_one[-(i+1):]\n",
    "\n",
    "            cnt = 0\n",
    "            for j in align_forw, align_back:\n",
    "                part_score = np_score(j)*match + np_score(j, zeros=False)*mismatch\n",
    "\n",
    "                if part_score >= score:\n",
    "                    score = part_score\n",
    "                    if cnt > 0:\n",
    "                        diff = max_lenght_seq -i -1\n",
    "                    else:\n",
    "                        diff = -(min_length_seq -i -1)\n",
    "                cnt += 1\n",
    "        \n",
    "        if i >= min_length_seq:\n",
    "            align_forw = seq_one[i-min_length_seq+1:(i+1)] - seq_two[-(i+1):]\n",
    "            align_back = seq_one[-(i+1):-(i-min_length_seq+1)] - seq_two[:(i+1)]\n",
    "\n",
    "            cnt = 0\n",
    "            for j in align_forw, align_back:\n",
    "                part_score = np_score(j)*match + np_score(j, zeros=False)*mismatch\n",
    "\n",
    "                \n",
    "                if part_score >= score:\n",
    "                    score = part_score\n",
    "                    if cnt > 0:\n",
    "                        diff = max_lenght_seq -i -1\n",
    "                    else:\n",
    "                        diff = -(min_length_seq -i -1)\n",
    "                cnt += 1 \n",
    "\n",
    "        if i == (num_iteration_int - 1) and alone:\n",
    "            i += 1\n",
    "\n",
    "            align_forw = seq_one[i-min_length_seq+1:(i+1)] - seq_two[-(i+1):]\n",
    "            part_score = np_score(j)*match + np_score(j, zeros=False)*mismatch\n",
    "\n",
    "            if part_score >= score:\n",
    "                score = part_score\n",
    "                diff = max_lenght_seq -i -1\n",
    "\n",
    "\n",
    "    return (score, diff, switch)\n",
    "\n",
    "np_align_func(c,b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
